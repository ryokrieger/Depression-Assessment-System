{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a3213d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Socio-Clinical Depression Assessment System ‚Äî Feature Engineering & Selection\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"viridis\", font_scale=1.1)\n",
    "print(\"‚úÖ Libraries loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93c425a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded. Shape: (2028, 39)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>University</th>\n",
       "      <th>Department</th>\n",
       "      <th>Academic_Year</th>\n",
       "      <th>Current_CGPA</th>\n",
       "      <th>waiver_or_scholarship</th>\n",
       "      <th>PSS1</th>\n",
       "      <th>PSS2</th>\n",
       "      <th>PSS3</th>\n",
       "      <th>...</th>\n",
       "      <th>PHQ2</th>\n",
       "      <th>PHQ3</th>\n",
       "      <th>PHQ4</th>\n",
       "      <th>PHQ5</th>\n",
       "      <th>PHQ6</th>\n",
       "      <th>PHQ7</th>\n",
       "      <th>PHQ8</th>\n",
       "      <th>PHQ9</th>\n",
       "      <th>Depression_Value</th>\n",
       "      <th>Depression_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18-22</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50 - 2.99</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18-22</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00 - 3.39</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00 - 3.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00 - 3.39</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18-22</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50 - 2.99</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender  University  Department  Academic_Year Current_CGPA  \\\n",
       "0  18-22       0           8           2              3  2.50 - 2.99   \n",
       "1  18-22       1           8           2              4  3.00 - 3.39   \n",
       "2  18-22       1           0           2              4  3.00 - 3.39   \n",
       "3  18-22       1           0           2              4  3.00 - 3.39   \n",
       "4  18-22       1          10           2              3  2.50 - 2.99   \n",
       "\n",
       "   waiver_or_scholarship  PSS1  PSS2  PSS3  ...  PHQ2  PHQ3  PHQ4  PHQ5  PHQ6  \\\n",
       "0                      0     3     4     3  ...     2     3     2     2     2   \n",
       "1                      0     3     3     4  ...     2     2     2     2     2   \n",
       "2                      0     0     0     0  ...     0     0     0     0     0   \n",
       "3                      0     3     1     2  ...     1     2     1     2     1   \n",
       "4                      0     4     4     4  ...     3     3     3     1     3   \n",
       "\n",
       "   PHQ7  PHQ8  PHQ9 Depression_Value  Depression_Label  \n",
       "0     2     3     2               20                 5  \n",
       "1     2     2     2               19                 3  \n",
       "2     0     0     0                0                 4  \n",
       "3     2     2     1               14                 2  \n",
       "4     0     3     3               20                 5  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DIR = os.path.abspath(\"..\")\n",
    "DATA_PROCESSED = os.path.join(BASE_DIR, \"data\", \"processed\")\n",
    "data_path = os.path.join(DATA_PROCESSED, \"mhp_cleaned.csv\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"‚úÖ Dataset loaded. Shape: {df.shape}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9057f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Leak columns removed. Remaining columns: 33\n"
     ]
    }
   ],
   "source": [
    "leak_cols = [\n",
    "    \"Depression_Value\", \"Depression_Label\",\n",
    "    \"Anxiety_Value\", \"Anxiety_Label\",\n",
    "    \"Stress_Value\", \"Stress_Label\"\n",
    "]\n",
    "\n",
    "df = df.drop(columns=[c for c in leak_cols if c in df.columns])\n",
    "print(f\"‚úÖ Leak columns removed. Remaining columns: {df.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9634127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Encoded categorical columns: ['Age', 'Current_CGPA']\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "categorical_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "print(\"‚úÖ Encoded categorical columns:\", categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b23e33e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSS features: 10, GAD features: 7, PHQ features: 9\n"
     ]
    }
   ],
   "source": [
    "# Load target from original clean dataset\n",
    "target_path = os.path.join(DATA_PROCESSED, \"mhp_cleaned.csv\")\n",
    "target_df = pd.read_csv(target_path)\n",
    "y = target_df[\"Depression_Label\"]\n",
    "\n",
    "# Identify feature groups\n",
    "pss_cols = [col for col in df.columns if col.startswith(\"PSS\")]\n",
    "gad_cols = [col for col in df.columns if col.startswith(\"GAD\")]\n",
    "phq_cols = [col for col in df.columns if col.startswith(\"PHQ\")]\n",
    "\n",
    "print(f\"PSS features: {len(pss_cols)}, GAD features: {len(gad_cols)}, PHQ features: {len(phq_cols)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1835879e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Top 5 features from each group:\n",
      "PSS: ['PSS1', 'PSS2', 'PSS3', 'PSS4', 'PSS10']\n",
      "GAD: ['GAD1', 'GAD4', 'GAD5', 'GAD6', 'GAD7']\n",
      "PHQ: ['PHQ2', 'PHQ3', 'PHQ4', 'PHQ6', 'PHQ7']\n",
      "\n",
      "Final selected features (15 total): ['PSS1', 'PSS2', 'PSS3', 'PSS4', 'PSS10', 'GAD1', 'GAD4', 'GAD5', 'GAD6', 'GAD7', 'PHQ2', 'PHQ3', 'PHQ4', 'PHQ6', 'PHQ7']\n"
     ]
    }
   ],
   "source": [
    "def select_top_k_features(X, y, feature_group, k=5):\n",
    "    selector = SelectKBest(score_func=f_classif, k=min(k, len(feature_group)))\n",
    "    selector.fit(df[feature_group], y)\n",
    "    selected_indices = selector.get_support(indices=True)\n",
    "    return [feature_group[i] for i in selected_indices]\n",
    "\n",
    "top_pss = select_top_k_features(df, y, pss_cols, k=5)\n",
    "top_gad = select_top_k_features(df, y, gad_cols, k=5)\n",
    "top_phq = select_top_k_features(df, y, phq_cols, k=5)\n",
    "\n",
    "selected_features = top_pss + top_gad + top_phq\n",
    "\n",
    "print(\"‚úÖ Top 5 features from each group:\")\n",
    "print(\"PSS:\", top_pss)\n",
    "print(\"GAD:\", top_gad)\n",
    "print(\"PHQ:\", top_phq)\n",
    "print(\"\\nFinal selected features (15 total):\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe06f00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data ready. Train: (1622, 15), Test: (406, 15)\n"
     ]
    }
   ],
   "source": [
    "X = df[selected_features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[selected_features] = scaler.fit_transform(X_train[selected_features])\n",
    "X_test[selected_features]  = scaler.transform(X_test[selected_features])\n",
    "\n",
    "print(f\"‚úÖ Data ready. Train: {X_train.shape}, Test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a839c033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Saved:\n",
      "- Feature list ‚Üí d:\\Study\\CSE299\\Depression Assessment System\\models\\feature_list.txt\n",
      "- Train ‚Üí d:\\Study\\CSE299\\Depression Assessment System\\data\\processed\\train_data.csv\n",
      "- Test ‚Üí d:\\Study\\CSE299\\Depression Assessment System\\data\\processed\\test_data.csv\n"
     ]
    }
   ],
   "source": [
    "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# Save feature list\n",
    "feature_path = os.path.join(MODELS_DIR, \"feature_list.txt\")\n",
    "with open(feature_path, \"w\") as f:\n",
    "    for feat in selected_features:\n",
    "        f.write(f\"{feat}\\n\")\n",
    "\n",
    "# Save datasets\n",
    "train_df = pd.concat([X_train, y_train.rename(\"Depression_Label\")], axis=1)\n",
    "test_df  = pd.concat([X_test, y_test.rename(\"Depression_Label\")], axis=1)\n",
    "\n",
    "train_path = os.path.join(DATA_PROCESSED, \"train_data.csv\")\n",
    "test_path = os.path.join(DATA_PROCESSED, \"test_data.csv\")\n",
    "\n",
    "train_df.to_csv(train_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "\n",
    "print(f\"üìÅ Saved:\\n- Feature list ‚Üí {feature_path}\\n- Train ‚Üí {train_path}\\n- Test ‚Üí {test_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1da20f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Automated Feature Selection Summary:\n",
      "1. Removed target leakage.\n",
      "2. Encoded categorical variables.\n",
      "3. Automatically picked top 5 features each from PSS, GAD, and PHQ using ANOVA F-test.\n",
      "4. Scaled and split data.\n",
      "5. Saved final train/test datasets and feature list.\n",
      "Next step ‚Üí 04_modeling_baselines.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "‚úÖ Automated Feature Selection Summary:\n",
    "1. Removed target leakage.\n",
    "2. Encoded categorical variables.\n",
    "3. Automatically picked top 5 features each from PSS, GAD, and PHQ using ANOVA F-test.\n",
    "4. Scaled and split data.\n",
    "5. Saved final train/test datasets and feature list.\n",
    "Next step ‚Üí 04_modeling_baselines.ipynb\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
